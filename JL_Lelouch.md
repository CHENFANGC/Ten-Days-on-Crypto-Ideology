---
timezone: Asia/Shanghai
---


---

# JL_Lelouch

1. 自我介绍
2. 你认为你会完成本次残酷学习吗？
3. 你的联系方式（推荐 Telegram）

## Notes

<!-- Content_START -->

### 2025.02.20
《Vitalik Buterin：我的技术乐观主义》

文中提到人们很容易忽视技术在基础设施上的改善，比如外卖，网约车，在线地图这些东西的出现，它们逐渐成为生活中熟悉的一部分，以至于很难再估计它们的好处和影响。事实上，科技在这方面确实帮助人类跨上了新的台阶，重塑了人类社会生活，进而对文化也产生了影响。也确实存在环境污染和与之而来的种种问题，但技术在持续的进步，在政府的有意识控制下，这些问题是可以被解决的。所以最终大家还是都走了先发展后治理的老路。

### 2025.02.21
《Vitalik Buterin：我的技术乐观主义》
ai总是被认为与其他的技术不同，它有极大可能带来风险并导致失控。人们对ai的观念似乎两极分化，一部分人坚信它能超越人类智慧的极限，在各方面辅助人类，另一部分则认为它最终会走向控制人类的道路。
人工智能会自行诞生出意义来吗？
政治集权在数字化的当今愈发容易实现，人们逐渐都被纳入监管之下，这在之后是否会演变成少数精英利用技术控制整个国家，尤其是战争当中。
> “不需要政治和意识形态工作和战争动员”意味着最高战争指挥官只需考虑战局本身，无需关心‘棋盘上的骑士和车’在想什么。战争变成了纯粹的技术比拼。

防御性治理，当冲突发生的可能性降低时，治理模式会更加自由开放。
人们更愿意对公共利益的益处投票，而不愿对害处投票，大家天然回避负面问题，以至于这类问题更容易到一个中央团体解决。
> 我热爱科技，因为科技拓展了人类的潜能。

计算机如何发展到人类智慧极限以上呢？怎么才能判断那是更智慧的生命体？智慧发展到一定程度是会更加包容的吗？还是说人们对人工智能可能的恐惧不在于它的智慧，而在于它不够智慧，却又格外强大？
部分人或许愿意将脑意识与计算机结合，部分人或许不愿意，那最终人类会因此分层为不同的人种吗？


### 2025.02.22
### 2025.02.23
《Vitalik：D/acc 一年后》
d/acc 的核心思想简洁明了：去中心化、民主且差异化的防御性加速。构建能够促使攻防平衡向防御倾斜的技术，并且在实施过程中不依赖于将更多权力交予中央权威机构。这两个方面之间存在着内在的紧密联系：任何一种去中心化、民主或自由的政治结构，在防御易于实施时往往能够蓬勃发展，而在防御面临重重困难时则会遭遇严峻挑战——在那些情况下，更有可能出现的结果是一段所有人相互对抗的混乱时期，最终达成由最强者统治的平衡状态。


### 2025.02.24
> 我们需要 ZK 来解锁三大改进。

> 首先，我们需要在允许自我监管和合规的同时保留用户选择，我们作为一个社区和生态系统还没有真正谈论过自我监管，我们只是希望并祈祷别人不会注意到。
我们不会达到目标，如果我们允许这种情况发生，Web3 不会成功。我们需要向某人证明我们在互相照顾和照顾我们的用户，所以我们需要向用户证明我们作为一个社区在支持他们。
我们不要试图把意识形态强加给用户，让我们给他们选择他们想去的地方，这最终是这个空间的意义所在，它是关于自由，关于自主。
最后，我们需要提高安全性，我们需要让它可靠，我们需要让加密成为必需品而不是可选品。我们忘记了政府至少据称是由选民组成的，为什么 Uber 和 Airbnb 曾经是非法的，现在又合法了？因为有人走到国会台阶上说“除非我死了，否则你不能拿走我的 Uber”，有人这么做了，个人这么做了，我不知道你们是否记得这件事。

> 我们让加密成为必需品并融入我们经济生活结构的一种方式是确保它是可靠和安全的，并且我们支持我们的用户。

> 这就是我们如何把“柠檬”变成“桃子”的方法。


### 2025.02.25
技术封建主义是指我们通过交出数据来访问大型科技领主（亚马逊、谷歌、苹果和 Meta）的云空间，从而为这些领主服务。
技术封建主义认为我们的偏好不再是我们自己的，而是由机器网络（通常称为云）制造的。它的基础理论是，云创建了一个反馈循环，消除了我们的能动性。我们训练算法来找到我们喜欢的东西，然后算法训练我们喜欢它提供的东西。
“我们需要的是社会对算法的控制。问题不在于算法对我们了解多少，而在于谁拥有算法？有组织的民主社会如何才能控制算法以造福大多数人？”他说。
“所有政治问题都有政治解决方案。困难在于组织起来，并将我们的集体利益转化为集体行动。
**“但自民主诞生以来，这一直是一个政治问题。”**
<!-- Content_END -->
